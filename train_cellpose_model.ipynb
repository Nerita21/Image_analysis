{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwRIqumQu7Mz"
      },
      "source": [
        "Check GPU avaiability (Runtime -> change runtime type -> hardware escalator -> T4 GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S23CE4iQu9ZZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKZ_AiUewpzN"
      },
      "source": [
        "Import environment, packages, load paths, data and prepare the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpd_TnLOXr8A"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTTYy8cevuxJ"
      },
      "source": [
        "Adjust the paths to your image, mask, model folders (/content/drive/MyDrive/...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh-c2kPHvZLM"
      },
      "outputs": [],
      "source": [
        "# Define directories in Google Drive\n",
        "drive_data_image_dir = \"/content/drive/MyDrive/cellpose/images_to_train/tiff\"\n",
        "drive_data_mask_dir = \"/content/drive/MyDrive/cellpose/images_to_train/training_material\"\n",
        "drive_data_test_dir = \"/content/drive/MyDrive/cellpose/images_to_train/test\"\n",
        "drive_model_dir = \"/content/drive/MyDrive/cellpose/model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfc2MBPlwy44"
      },
      "outputs": [],
      "source": [
        "# Clone/update repository\n",
        "! rm -rf /content/Image_analysis\n",
        "! git clone https://github.com/Nerita21/Image_analysis.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grNZHpoDw3WJ"
      },
      "outputs": [],
      "source": [
        "# Install packages from requirements only if missing\n",
        "import subprocess\n",
        "import sys\n",
        "import importlib.util\n",
        "import os\n",
        "\n",
        "def ensure_requirements(req_file=\"requirements.txt\"):\n",
        "    if not os.path.exists(req_file):\n",
        "        # Try to find requirements.txt in the cloned repository directory\n",
        "        repo_dir = \"/content/Image_analysis\"\n",
        "        if os.path.exists(os.path.join(repo_dir, req_file)):\n",
        "            req_file = os.path.join(repo_dir, req_file)\n",
        "        else:\n",
        "            print(f\"Error: requirements.txt not found at {req_file} or {os.path.join(repo_dir, 'requirements.txt')}\")\n",
        "            return\n",
        "\n",
        "    with open(req_file) as f:\n",
        "        for line in f:\n",
        "            pkg = line.strip()\n",
        "            if not pkg or pkg.startswith(\"#\"):\n",
        "                continue\n",
        "\n",
        "            # Pip typically expects '==' for exact version pinning.\n",
        "            # If the requirement uses '=', try to convert it to '=='\n",
        "            # if it looks like a simple package=version string and not a URL or path.\n",
        "            processed_pkg = pkg\n",
        "            if '=' in pkg and '==' not in pkg and not any(x in pkg for x in ['/', 'git+', '#egg=']):\n",
        "                parts = pkg.split('=', 1)\n",
        "                if len(parts) == 2 and parts[1]: # ensure there's a version part\n",
        "                    processed_pkg = f\"{parts[0]}=={parts[1]}\"\n",
        "\n",
        "            name = pkg.split(\"==\")[0].split(\">=\")[0].split(\"<=\")[0].split(\"=\")[0]\n",
        "            if importlib.util.find_spec(name) is None:\n",
        "                print(f\"Installing {processed_pkg}...\")\n",
        "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", processed_pkg])\n",
        "            else:\n",
        "                print(f\"{name} already installed.\")\n",
        "\n",
        "ensure_requirements()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvSV_uGTxXd0"
      },
      "outputs": [],
      "source": [
        "# Import required packages:\n",
        "from cellpose import models, utils\n",
        "import napari\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import os\n",
        "import tifffile\n",
        "import numpy as np\n",
        "import statannotations.Annotator as Annotator\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiUqPohwxYet"
      },
      "outputs": [],
      "source": [
        "# Now you can import your packages\n",
        "import sys\n",
        "sys.path.insert(0, '/content/Image_analysis/src')   # adjust path if you cloned elsewhere\n",
        "from utils import load_config\n",
        "config, base_dir = load_config()\n",
        "\n",
        "from package import (train_cellpose_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvlZ-MBS06PL"
      },
      "source": [
        "Run model training manually after adjusting the inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Convert string paths to Path objects\n",
        "    image_dir_path = Path(drive_data_image_dir)\n",
        "    mask_dir_path = Path(drive_data_mask_dir)\n",
        "    test_dir_path = Path(drive_data_test_dir)\n",
        "\n",
        "    model_path = os.path.join(drive_model_dir, \"noisyFISH_cyto\") # rename for your choice\n",
        "\n",
        "    # Train model\n",
        "    try:\n",
        "        model = train_cellpose_model(\n",
        "            image_dir=image_dir_path,\n",
        "            mask_dir=mask_dir_path,\n",
        "            test_dir=test_dir_path,\n",
        "            model_name= model_path, \n",
        "            channel_id = \"ch2\",\n",
        "            n_epochs=100,\n",
        "            batch_size=4,\n",
        "            learning_rate=0.01,\n",
        "        )\n",
        "        print(\"\\n Training complete!\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n Training failed: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
